{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yX8Bz8EU5qad"
   },
   "source": [
    "# Detecting electrode inversion in an ECG\n",
    "\n",
    "\n",
    "The ECG is a time series that measures the electrical activity of the heart. This is the main tool to diagnose heart diseases. Recording an ECG is simple: 3 electrodes are placed at the ends of limbs, and 6 on the anterior chest.This generates **12 time series**, called leads, each corresponding to a difference in potential between a pair of electrodes.\n",
    "\n",
    "The electrodes' position is very important to correctly interpret the ECG. Making the mistake of inverting electrodes compromises interpretation, either because the leads do not explore the expected area (errors in the measures of hypertrophia indices, in the analysis of the ST segment), or because they generate false abnormalities (fake Q waves, error in the heart's axis...).\n",
    "\n",
    "Inversion errors are frequent (5% of ECGs), and only experts (cardiologists) manage to detect them. But most ECGs are not interpreted by experts: only 30% are, the rest being interpreted by nurses or general practitioners. An algorithm for automatic detection of electrode inversion is therefore paramount to the correct interpretation of ECGs  and would improve the quality of diagnosis.\n",
    "\n",
    "This project is intended to make you detect electrode inversion in an ECG. The dataset at your disposal contains ECGs from a cardiology center. **An ECG will be labeled as correctly realised (0) or as inverted (1).**\n",
    "The goal is to perform **binary classification** on these ECGs.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "## Inversions\n",
    "\n",
    "Inversions do not necessarily correspond to the inversion of only 2 leads:\n",
    "* Precordial leads from (V1, ..., V6) can be inverted: V1 becomes V6, V2 becomes V5...\n",
    "* 2 electrodes can be exchanged, which modifies several leads from ML1, ML2, ML3, AVF, AVR, AVL. For instance, if electrodes of the right and left arms are inverted, then ML1 becomes -ML1, ML2 and ML3 are inverted, AVL and AVR are inverted and AVF remains the same. More details here: https://litfl.com/ecg-limb-lead-reversal-ecg-library/\n",
    "\n",
    "\n",
    "## Data\n",
    "\n",
    "Data is available at the following link:\n",
    "https://drive.google.com/file/d/1tdjqbkRNqxfDdNbb6pXiX8DvCaFlMOjd/view?usp=sharing\n",
    "\n",
    "In the archive, you will find:\n",
    "* input_training.npy\n",
    "* output_training.npy\n",
    "* input_test.npy\n",
    "\n",
    "The training data contains 1400 ECGs and their labels. For each ECG, the data consists of **10 seconds** of recording for **12 leads**, each sampled at **250Hz**.\n",
    "\n",
    "The testing data contains 2630 ECGs on which you will give your predictions at the end of the homework in a numpy array with a shape (2630,).\n",
    "\n",
    "Each input file therefore contains the ECG signal in the form **(n_ecgs, n_samples=2500, n_leads=12)**.\n",
    "\n",
    "## Code\n",
    "\n",
    "You are free to choose the libraries you use for your implementations.\n",
    "Use of Keras is preferred for conciseness, but you can use a different DL library if you are unfamiliar with Keras. This will not affect evaluation of the notebook.\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "We will use **accuracy** as a metric to evaluate your predictions on the test set.\n",
    "\n",
    "\n",
    "## Objective\n",
    "\n",
    "The key objective of this homework is to propose a **deep learning model** relevant to the task that shows good accuracy in detection of lead inversion. A strong notebook should be readable, reproducible and the code must be clean.\n",
    "\n",
    "Please send back:\n",
    "- a Jupyter Notebook explaining your process and commenting your results,\n",
    "- a npy file containing the predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7184,
     "status": "ok",
     "timestamp": 1700337434077,
     "user": {
      "displayName": "Samuel Otofa",
      "userId": "05188918829679889280"
     },
     "user_tz": -60
    },
    "id": "vfy8ksUCMZL0",
    "outputId": "abe66ca7-b7b7-4e21-f9ba-c66d153a8343"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ecg_plot\n",
      "  Downloading ecg_plot-0.2.8-py3-none-any.whl (9.2 kB)\n",
      "Installing collected packages: ecg_plot\n",
      "Successfully installed ecg_plot-0.2.8\n"
     ]
    }
   ],
   "source": [
    "!pip install ecg_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 6300,
     "status": "ok",
     "timestamp": 1700360742810,
     "user": {
      "displayName": "Samuel Otofa",
      "userId": "05188918829679889280"
     },
     "user_tz": -60
    },
    "id": "fgDYLuyuEPqp"
   },
   "outputs": [],
   "source": [
    "!pip install keras-tuner -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 191,
     "status": "ok",
     "timestamp": 1700360806750,
     "user": {
      "displayName": "Samuel Otofa",
      "userId": "05188918829679889280"
     },
     "user_tz": -60
    },
    "id": "x3epyv1p6gtC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import ecg_plot\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import signal\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from keras_tuner import RandomSearch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5I0afL95qah"
   },
   "source": [
    "## 1. Load and analyze the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1700360747098,
     "user": {
      "displayName": "Samuel Otofa",
      "userId": "05188918829679889280"
     },
     "user_tz": -60
    },
    "id": "FQNyvKHt6Qms"
   },
   "outputs": [],
   "source": [
    "data = np.load('data/input_training.npy')\n",
    "labels = np.load('data/output_training.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jhs0oNSGdkBA"
   },
   "source": [
    "Data preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1700360747099,
     "user": {
      "displayName": "Samuel Otofa",
      "userId": "05188918829679889280"
     },
     "user_tz": -60
    },
    "id": "EZ2YfN5emi3m"
   },
   "outputs": [],
   "source": [
    "def data_preprocessing(raw_data):\n",
    "  preprocessed_data = np.empty((raw_data.shape[0],2500,12))\n",
    "  for i in range(len(raw_data)):\n",
    "    single_ecg = raw_data[i]\n",
    "    ecg_moveaxis = single_ecg.T\n",
    "    preprocessed_data[i] =  ecg_moveaxis\n",
    "  return preprocessed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 531,
     "status": "ok",
     "timestamp": 1700360750217,
     "user": {
      "displayName": "Samuel Otofa",
      "userId": "05188918829679889280"
     },
     "user_tz": -60
    },
    "id": "onk0OgDnyIaW"
   },
   "outputs": [],
   "source": [
    "X = data_preprocessing(data)\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,labels, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1700360752306,
     "user": {
      "displayName": "Samuel Otofa",
      "userId": "05188918829679889280"
     },
     "user_tz": -60
    },
    "id": "fN_bnZ9Y0J4q",
    "outputId": "84532d90-beb5-42ec-c112-94162e999a33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120, 2500, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WKiBu5hA5qai"
   },
   "source": [
    "## 2. Classification using the raw signal\n",
    "The goal here is to perform classification using directly the raw data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0s4fDVTb5qaj"
   },
   "source": [
    "### a) Which variant of neural networks would be more adequate for the task? (RNN, CNN, DNN...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23Nwzgc_5qaj"
   },
   "source": [
    "\n",
    "\n",
    "*Your answer: I decide to use a CNN architecture because my goal is to extract features from each lead, so if we consider a lead data as a image the best way to extract features on a image is with CNN*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpxGC6415qak"
   },
   "source": [
    "### b) Train and evaluate a classifier using the raw signal\n",
    "Train and evaluate the method of your choice using only the signal from the training set.\n",
    "\n",
    "We expect:\n",
    "- a simple architecture relevant for the task\n",
    "- a model converging without overfitting\n",
    "- high performances on the testing set\n",
    "\n",
    "Note: It is not complicated to reach an accuracy of 85% on the testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQeJGQin3I-q"
   },
   "source": [
    "**model buildind and hyperparmeters optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 200,
     "status": "ok",
     "timestamp": 1700360765898,
     "user": {
      "displayName": "Samuel Otofa",
      "userId": "05188918829679889280"
     },
     "user_tz": -60
    },
    "id": "LrtcnVMkNiRn"
   },
   "outputs": [],
   "source": [
    "x_train_search,x_val,y_train_seach,y_val =  train_test_split(x_train,y_train, test_size=0.20, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 254,
     "status": "ok",
     "timestamp": 1700360756936,
     "user": {
      "displayName": "Samuel Otofa",
      "userId": "05188918829679889280"
     },
     "user_tz": -60
    },
    "id": "sxdJuF--zuym"
   },
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    inputlayer = keras.layers.Input(shape=(2500,12))\n",
    "\n",
    "    conv1 = keras.layers.Conv1D(filters=hp.Int('conv_1_filter', min_value=8, max_value=200, step=10), kernel_size=hp.Int('conv_1_kernel', min_value=5, max_value=30, step=10), padding='same')(inputlayer)\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = keras.layers.Activation(activation='relu')(conv1)\n",
    "    conv1 = keras.layers.SpatialDropout1D(0.1)(conv1)\n",
    "\n",
    "    conv2 = keras.layers.Conv1D(filters=hp.Int('conv_2_filter', min_value=16, max_value=300, step=10), kernel_size=hp.Int('conv_2_kernel', min_value=5, max_value=30, step=5), padding='same')(conv1)\n",
    "    conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = keras.layers.Activation('relu')(conv2)\n",
    "    conv2 = keras.layers.SpatialDropout1D(0.1)(conv2)\n",
    "\n",
    "    conv3 = keras.layers.Conv1D(filters=hp.Int('conv_3_filter', min_value=12, max_value=600, step=10), kernel_size=hp.Int('conv_3_kernel', min_value=5, max_value=30, step=5),padding='same')(conv2)\n",
    "    conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = keras.layers.Activation('relu')(conv3)\n",
    "    conv3 = keras.layers.Dropout(0.2)(conv3)\n",
    "\n",
    "    gap_layer = keras.layers.GlobalAveragePooling1D()(conv3)\n",
    "\n",
    "\n",
    "    output_layer = tf.keras.layers.Dense(units=1,activation='sigmoid', name='output_layer')(gap_layer)\n",
    "\n",
    "    model = keras.Model(inputs=inputlayer, outputs=output_layer)\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy', dtype=None, threshold=0.5)])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1561698,
     "status": "ok",
     "timestamp": 1700362442978,
     "user": {
      "displayName": "Samuel Otofa",
      "userId": "05188918829679889280"
     },
     "user_tz": -60
    },
    "id": "IDdP75UhNz6x",
    "outputId": "cfc3843e-4c1c-4872-9fcb-29cc6329c19c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 05m 24s]\n",
      "val_accuracy: 0.9464285969734192\n",
      "\n",
      "Best val_accuracy So Far: 0.9553571343421936\n",
      "Total elapsed time: 00h 26m 00s\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(build_model,\n",
    "                    objective='val_accuracy',\n",
    "                    max_trials = 5)\n",
    "tuner.search(x_train_search,y_train_seach,epochs=100,validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUk5BC6pnLrS"
   },
   "source": [
    "Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 749,
     "status": "ok",
     "timestamp": 1700362471212,
     "user": {
      "displayName": "Samuel Otofa",
      "userId": "05188918829679889280"
     },
     "user_tz": -60
    },
    "id": "nEQUTY8FHYkV",
    "outputId": "c43cda9b-a16c-474a-994a-7dd7cb378913"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 2500, 12)]        0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 2500, 68)          12308     \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 2500, 68)          272       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " activation (Activation)     (None, 2500, 68)          0         \n",
      "                                                                 \n",
      " spatial_dropout1d (Spatial  (None, 2500, 68)          0         \n",
      " Dropout1D)                                                      \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 2500, 266)         362026    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 2500, 266)         1064      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 2500, 266)         0         \n",
      "                                                                 \n",
      " spatial_dropout1d_1 (Spati  (None, 2500, 266)         0         \n",
      " alDropout1D)                                                    \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 2500, 12)          79812     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 2500, 12)          48        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 2500, 12)          0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2500, 12)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 12)                0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 455543 (1.74 MB)\n",
      "Trainable params: 454851 (1.74 MB)\n",
      "Non-trainable params: 692 (2.70 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_model=tuner.get_best_models(num_models=1)[0]\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 264605,
     "status": "ok",
     "timestamp": 1700362742808,
     "user": {
      "displayName": "Samuel Otofa",
      "userId": "05188918829679889280"
     },
     "user_tz": -60
    },
    "id": "CguCFp_00HrP",
    "outputId": "4b430b1c-e741-46f1-c50a-6cc045e6cd61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 [==============================] - 6s 124ms/step - loss: 0.1299 - accuracy: 0.9554 - val_loss: 0.1706 - val_accuracy: 0.9777 - lr: 0.0010\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 3s 96ms/step - loss: 0.1184 - accuracy: 0.9565 - val_loss: 0.0991 - val_accuracy: 0.9554 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.1140 - accuracy: 0.9542 - val_loss: 0.1075 - val_accuracy: 0.9777 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0958 - accuracy: 0.9676 - val_loss: 0.0818 - val_accuracy: 0.9821 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0818 - accuracy: 0.9754 - val_loss: 0.0831 - val_accuracy: 0.9732 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.1022 - accuracy: 0.9621 - val_loss: 0.1352 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0902 - accuracy: 0.9688 - val_loss: 0.0904 - val_accuracy: 0.9777 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.1023 - accuracy: 0.9621 - val_loss: 0.0829 - val_accuracy: 0.9732 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0832 - accuracy: 0.9688 - val_loss: 0.0820 - val_accuracy: 0.9911 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0780 - accuracy: 0.9721 - val_loss: 0.0963 - val_accuracy: 0.9688 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0814 - accuracy: 0.9721 - val_loss: 0.1437 - val_accuracy: 0.9330 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0963 - accuracy: 0.9665 - val_loss: 0.1289 - val_accuracy: 0.9375 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.0848 - accuracy: 0.9676 - val_loss: 0.1980 - val_accuracy: 0.9062 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0797 - accuracy: 0.9710 - val_loss: 0.1011 - val_accuracy: 0.9688 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0980 - accuracy: 0.9654 - val_loss: 0.1863 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.1156 - accuracy: 0.9632 - val_loss: 0.2865 - val_accuracy: 0.8839 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0875 - accuracy: 0.9721 - val_loss: 0.0906 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0943 - accuracy: 0.9643 - val_loss: 0.0969 - val_accuracy: 0.9688 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0777 - accuracy: 0.9743 - val_loss: 0.0941 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0648 - accuracy: 0.9743 - val_loss: 0.0889 - val_accuracy: 0.9688 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0784 - accuracy: 0.9699 - val_loss: 0.0952 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0705 - accuracy: 0.9754 - val_loss: 0.1061 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0729 - accuracy: 0.9754 - val_loss: 0.0936 - val_accuracy: 0.9688 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 3s 106ms/step - loss: 0.0706 - accuracy: 0.9777 - val_loss: 0.0714 - val_accuracy: 0.9866 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0690 - accuracy: 0.9766 - val_loss: 0.0777 - val_accuracy: 0.9777 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0695 - accuracy: 0.9777 - val_loss: 0.0870 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 3s 101ms/step - loss: 0.0769 - accuracy: 0.9732 - val_loss: 0.0667 - val_accuracy: 0.9866 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.0541 - accuracy: 0.9844 - val_loss: 0.1205 - val_accuracy: 0.9509 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0428 - accuracy: 0.9888 - val_loss: 0.0831 - val_accuracy: 0.9688 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0803 - accuracy: 0.9710 - val_loss: 0.0870 - val_accuracy: 0.9554 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0638 - accuracy: 0.9833 - val_loss: 0.1353 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 3s 101ms/step - loss: 0.0573 - accuracy: 0.9821 - val_loss: 0.0637 - val_accuracy: 0.9777 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0803 - accuracy: 0.9688 - val_loss: 0.1340 - val_accuracy: 0.9420 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0658 - accuracy: 0.9810 - val_loss: 0.0920 - val_accuracy: 0.9732 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0531 - accuracy: 0.9877 - val_loss: 0.1229 - val_accuracy: 0.9598 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0559 - accuracy: 0.9766 - val_loss: 0.0670 - val_accuracy: 0.9777 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0400 - accuracy: 0.9900 - val_loss: 0.0774 - val_accuracy: 0.9732 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0545 - accuracy: 0.9844 - val_loss: 0.1136 - val_accuracy: 0.9554 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0723 - accuracy: 0.9721 - val_loss: 0.1197 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0639 - accuracy: 0.9810 - val_loss: 0.0810 - val_accuracy: 0.9732 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0559 - accuracy: 0.9799 - val_loss: 0.0914 - val_accuracy: 0.9688 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0667 - accuracy: 0.9821 - val_loss: 0.0964 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0470 - accuracy: 0.9888 - val_loss: 0.0771 - val_accuracy: 0.9598 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0465 - accuracy: 0.9844 - val_loss: 0.0891 - val_accuracy: 0.9509 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0772 - accuracy: 0.9766 - val_loss: 0.1092 - val_accuracy: 0.9554 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0484 - accuracy: 0.9866 - val_loss: 0.1045 - val_accuracy: 0.9554 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0583 - accuracy: 0.9754 - val_loss: 0.0793 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0550 - accuracy: 0.9844 - val_loss: 0.1487 - val_accuracy: 0.9330 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0533 - accuracy: 0.9855 - val_loss: 0.1013 - val_accuracy: 0.9598 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0641 - accuracy: 0.9732 - val_loss: 0.0957 - val_accuracy: 0.9688 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0789 - accuracy: 0.9710 - val_loss: 0.1832 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0692 - accuracy: 0.9732 - val_loss: 0.0930 - val_accuracy: 0.9688 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0482 - accuracy: 0.9821 - val_loss: 0.0778 - val_accuracy: 0.9777 - lr: 5.0000e-04\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0523 - accuracy: 0.9855 - val_loss: 0.0827 - val_accuracy: 0.9732 - lr: 5.0000e-04\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0475 - accuracy: 0.9844 - val_loss: 0.0813 - val_accuracy: 0.9688 - lr: 5.0000e-04\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0459 - accuracy: 0.9821 - val_loss: 0.0686 - val_accuracy: 0.9777 - lr: 5.0000e-04\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0559 - accuracy: 0.9833 - val_loss: 0.0703 - val_accuracy: 0.9821 - lr: 5.0000e-04\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0444 - accuracy: 0.9866 - val_loss: 0.0787 - val_accuracy: 0.9777 - lr: 5.0000e-04\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0404 - accuracy: 0.9877 - val_loss: 0.1054 - val_accuracy: 0.9554 - lr: 5.0000e-04\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0362 - accuracy: 0.9866 - val_loss: 0.1091 - val_accuracy: 0.9464 - lr: 5.0000e-04\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0327 - accuracy: 0.9911 - val_loss: 0.1201 - val_accuracy: 0.9464 - lr: 5.0000e-04\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0360 - accuracy: 0.9888 - val_loss: 0.0736 - val_accuracy: 0.9732 - lr: 5.0000e-04\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0473 - accuracy: 0.9833 - val_loss: 0.0765 - val_accuracy: 0.9732 - lr: 5.0000e-04\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0265 - accuracy: 0.9955 - val_loss: 0.0772 - val_accuracy: 0.9777 - lr: 5.0000e-04\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0351 - accuracy: 0.9900 - val_loss: 0.0816 - val_accuracy: 0.9688 - lr: 5.0000e-04\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0289 - accuracy: 0.9911 - val_loss: 0.1070 - val_accuracy: 0.9554 - lr: 5.0000e-04\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.0352 - accuracy: 0.9900 - val_loss: 0.0798 - val_accuracy: 0.9688 - lr: 5.0000e-04\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0269 - accuracy: 0.9933 - val_loss: 0.0899 - val_accuracy: 0.9598 - lr: 5.0000e-04\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0361 - accuracy: 0.9877 - val_loss: 0.1078 - val_accuracy: 0.9554 - lr: 5.0000e-04\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0342 - accuracy: 0.9922 - val_loss: 0.0863 - val_accuracy: 0.9688 - lr: 5.0000e-04\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0280 - accuracy: 0.9933 - val_loss: 0.0644 - val_accuracy: 0.9688 - lr: 5.0000e-04\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0242 - accuracy: 0.9944 - val_loss: 0.0769 - val_accuracy: 0.9688 - lr: 5.0000e-04\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0204 - accuracy: 0.9944 - val_loss: 0.0806 - val_accuracy: 0.9688 - lr: 2.5000e-04\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0320 - accuracy: 0.9900 - val_loss: 0.0743 - val_accuracy: 0.9777 - lr: 2.5000e-04\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0318 - accuracy: 0.9900 - val_loss: 0.0761 - val_accuracy: 0.9732 - lr: 2.5000e-04\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0276 - accuracy: 0.9933 - val_loss: 0.0740 - val_accuracy: 0.9732 - lr: 2.5000e-04\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 3s 104ms/step - loss: 0.0299 - accuracy: 0.9933 - val_loss: 0.0628 - val_accuracy: 0.9821 - lr: 2.5000e-04\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0205 - accuracy: 0.9967 - val_loss: 0.0688 - val_accuracy: 0.9732 - lr: 2.5000e-04\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0437 - accuracy: 0.9877 - val_loss: 0.0735 - val_accuracy: 0.9688 - lr: 2.5000e-04\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0295 - accuracy: 0.9933 - val_loss: 0.0707 - val_accuracy: 0.9732 - lr: 2.5000e-04\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0316 - accuracy: 0.9944 - val_loss: 0.0682 - val_accuracy: 0.9821 - lr: 2.5000e-04\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0313 - accuracy: 0.9900 - val_loss: 0.0820 - val_accuracy: 0.9732 - lr: 2.5000e-04\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0292 - accuracy: 0.9911 - val_loss: 0.0876 - val_accuracy: 0.9598 - lr: 2.5000e-04\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0282 - accuracy: 0.9933 - val_loss: 0.0863 - val_accuracy: 0.9554 - lr: 2.5000e-04\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0298 - accuracy: 0.9955 - val_loss: 0.0715 - val_accuracy: 0.9732 - lr: 2.5000e-04\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0315 - accuracy: 0.9944 - val_loss: 0.0859 - val_accuracy: 0.9732 - lr: 2.5000e-04\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0274 - accuracy: 0.9944 - val_loss: 0.0725 - val_accuracy: 0.9777 - lr: 2.5000e-04\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0299 - accuracy: 0.9911 - val_loss: 0.0642 - val_accuracy: 0.9777 - lr: 2.5000e-04\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0379 - accuracy: 0.9900 - val_loss: 0.0736 - val_accuracy: 0.9688 - lr: 2.5000e-04\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0343 - accuracy: 0.9888 - val_loss: 0.0795 - val_accuracy: 0.9688 - lr: 2.5000e-04\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0293 - accuracy: 0.9922 - val_loss: 0.0688 - val_accuracy: 0.9777 - lr: 2.5000e-04\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0249 - accuracy: 0.9967 - val_loss: 0.0741 - val_accuracy: 0.9732 - lr: 2.5000e-04\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0391 - accuracy: 0.9900 - val_loss: 0.0679 - val_accuracy: 0.9732 - lr: 2.5000e-04\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0213 - accuracy: 0.9955 - val_loss: 0.0636 - val_accuracy: 0.9821 - lr: 2.5000e-04\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0273 - accuracy: 0.9888 - val_loss: 0.0926 - val_accuracy: 0.9732 - lr: 2.5000e-04\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0185 - accuracy: 0.9978 - val_loss: 0.0935 - val_accuracy: 0.9598 - lr: 2.5000e-04\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0284 - accuracy: 0.9922 - val_loss: 0.1152 - val_accuracy: 0.9554 - lr: 2.5000e-04\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0375 - accuracy: 0.9888 - val_loss: 0.0873 - val_accuracy: 0.9732 - lr: 1.2500e-04\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.0293 - accuracy: 0.9933 - val_loss: 0.0822 - val_accuracy: 0.9777 - lr: 1.2500e-04\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0204 - accuracy: 0.9933 - val_loss: 0.0838 - val_accuracy: 0.9732 - lr: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"best_model.h5\", save_best_only=True, monitor=\"val_loss\"\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
    "]\n",
    "history = my_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8MLWFselo4fR"
   },
   "source": [
    "Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFYzkYdYlH_b"
   },
   "source": [
    "evaluation on x_test and y_test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1049,
     "status": "ok",
     "timestamp": 1700364276547,
     "user": {
      "displayName": "Samuel Otofa",
      "userId": "05188918829679889280"
     },
     "user_tz": -60
    },
    "id": "j9LK9afB5qak",
    "outputId": "530e6377-52a5-4c42-bdeb-f6bc35fe55f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 24ms/step - loss: 0.1015 - accuracy: 0.9607\n",
      "Test accuracy 0.9607142806053162\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"best_model.h5\")\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(\"Test accuracy\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NsdYV14c5qal"
   },
   "source": [
    "### c) What would you explore to improve your results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3a81hkD45qal"
   },
   "source": [
    "*Your answer: To improve my results, I will try to find a certain data pre-processing that will allow better detection of electrode inversion by the model, and I will also test other RNN or DNN-based architectures.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__y1WTky5qam"
   },
   "source": [
    "## 3. Prediction on the test set\n",
    "Use the output model of section 2 to make predictions on the testing set.\n",
    "\n",
    "**Save your predictions in a file predictions.npy that you will send along with your notebook.**\n",
    "\n",
    "The expected format is a binary array of shape (n_ecgs=2630,) where each value corresponds to the prediction on the corresponding ECG of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 292,
     "status": "ok",
     "timestamp": 1700364223451,
     "user": {
      "displayName": "Samuel Otofa",
      "userId": "05188918829679889280"
     },
     "user_tz": -60
    },
    "id": "YsGW3FtErx1A"
   },
   "outputs": [],
   "source": [
    "#prediction on raw data\n",
    "\n",
    "def predict(raw_data):\n",
    "  #preprocess raw_data\n",
    "  eval_set = data_preprocessing(raw_data)\n",
    "  #build_prediction\n",
    "  real_predictions = np.empty(len(eval_set))\n",
    "  model = keras.models.load_model(\"best_model.h5\")\n",
    "  predictions = model.predict(eval_set)\n",
    "  for i in range(len(predictions)):\n",
    "    pred = predictions[i]\n",
    "    if pred[0]>0.5:\n",
    "      real_predictions[i] = 1\n",
    "    else:\n",
    "      real_predictions[i] = 0\n",
    "\n",
    "  return real_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 184,
     "status": "ok",
     "timestamp": 1700364184229,
     "user": {
      "displayName": "Samuel Otofa",
      "userId": "05188918829679889280"
     },
     "user_tz": -60
    },
    "id": "SwvbfeLllai5"
   },
   "outputs": [],
   "source": [
    "def predict_and_score_on_raw_data(raw_data,raw_data_labels):\n",
    "  #preprocess raw_data\n",
    "  eval_set = data_preprocessing(raw_data)\n",
    "  #build_prediction\n",
    "  real_predictions = np.empty(len(eval_set))\n",
    "  model = keras.models.load_model(\"best_model.h5\")\n",
    "  predictions = model.predict(eval_set)\n",
    "  for i in range(len(predictions)):\n",
    "    pred = predictions[i]\n",
    "    if pred[0]>0.5:\n",
    "      real_predictions[i] = 1\n",
    "    else:\n",
    "      real_predictions[i] = 0\n",
    "  print(f\"accuracy:{np.count_nonzero(real_predictions==labels)/len(labels)}\")\n",
    "  return real_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4851,
     "status": "ok",
     "timestamp": 1700363206305,
     "user": {
      "displayName": "Samuel Otofa",
      "userId": "05188918829679889280"
     },
     "user_tz": -60
    },
    "id": "oVH7yvpSbBRR",
    "outputId": "093b63eb-4cd4-4a2d-9607-ef29cb0b2dec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 2s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "evaluation_set = np.load('candidate_files/input_test_set.npy')\n",
    "predictions = predict(evaluation_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1700363254212,
     "user": {
      "displayName": "Samuel Otofa",
      "userId": "05188918829679889280"
     },
     "user_tz": -60
    },
    "id": "tA7E1Jpib0iS"
   },
   "outputs": [],
   "source": [
    "np.save(\"predictions.npy\", predictions)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
